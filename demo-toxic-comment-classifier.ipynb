{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:34:02.867310Z","iopub.execute_input":"2022-07-13T14:34:02.868156Z","iopub.status.idle":"2022-07-13T14:34:29.080494Z","shell.execute_reply.started":"2022-07-13T14:34:02.868049Z","shell.execute_reply":"2022-07-13T14:34:29.079214Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.5.1.tar.gz (14 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.27.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.6.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.12)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nBuilding wheels for collected packages: gdown\n  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=904739b5b7505e9261b5b3caec316f869485784bef18f3742692b9d06ec6ea37\n  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\nSuccessfully built gdown\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!gdown 1xU9p1TTLU3_sFSF73NXMvk9t7N4HJEOJ","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:35:11.889749Z","iopub.execute_input":"2022-07-13T14:35:11.890797Z","iopub.status.idle":"2022-07-13T14:35:17.792343Z","shell.execute_reply.started":"2022-07-13T14:35:11.890751Z","shell.execute_reply":"2022-07-13T14:35:17.791091Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1xU9p1TTLU3_sFSF73NXMvk9t7N4HJEOJ\nTo: /kaggle/working/ToxicCommentClassifier/e2_loss0.1510_f1_score_0_91563.h5\n100%|█████████████████████████████████████████| 712M/712M [00:02<00:00, 238MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Клонирование репозитория и установка зависимостей","metadata":{"id":"fYqXpS16Wh4S"}},{"cell_type":"code","source":"!git clone https://github.com/ankkarp/ToxicCommentClassifier.git","metadata":{"id":"pVkZqzo_bwye","outputId":"ab09e088-9a4a-412e-879f-b9ab40f5b1f3","execution":{"iopub.status.busy":"2022-07-13T14:34:34.694847Z","iopub.execute_input":"2022-07-13T14:34:34.695533Z","iopub.status.idle":"2022-07-13T14:34:36.965959Z","shell.execute_reply.started":"2022-07-13T14:34:34.695477Z","shell.execute_reply":"2022-07-13T14:34:36.964792Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'ToxicCommentClassifier'...\nremote: Enumerating objects: 102, done.\u001b[K\nremote: Counting objects: 100% (102/102), done.\u001b[K\nremote: Compressing objects: 100% (77/77), done.\u001b[K\nremote: Total 102 (delta 56), reused 63 (delta 23), pack-reused 0\u001b[K\nReceiving objects: 100% (102/102), 1.37 MiB | 3.10 MiB/s, done.\nResolving deltas: 100% (56/56), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd ToxicCommentClassifier","metadata":{"id":"WqZz9jkTdBfk","outputId":"f35a24d8-37cd-4047-bd36-2bea176a0fd1","execution":{"iopub.status.busy":"2022-07-13T14:34:36.969192Z","iopub.execute_input":"2022-07-13T14:34:36.969965Z","iopub.status.idle":"2022-07-13T14:34:36.977152Z","shell.execute_reply.started":"2022-07-13T14:34:36.969926Z","shell.execute_reply":"2022-07-13T14:34:36.976004Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/ToxicCommentClassifier\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat requirements.txt","metadata":{"id":"CylKcsPS6Vmd","outputId":"61f4a7e2-d779-497d-8d88-3d6041f756c4","execution":{"iopub.status.busy":"2022-07-13T14:34:36.978540Z","iopub.execute_input":"2022-07-13T14:34:36.979031Z","iopub.status.idle":"2022-07-13T14:34:37.640925Z","shell.execute_reply.started":"2022-07-13T14:34:36.978982Z","shell.execute_reply":"2022-07-13T14:34:37.639717Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"certifi==2022.6.15\ncharset-normalizer==2.1.0\nclick==8.1.3\ncolorama==0.4.5\ndocker-pycreds==0.4.0\nfilelock==3.7.1\ngitdb==4.0.9\nGitPython==3.1.27\nhuggingface-hub==0.8.1\nidna==3.3\nnumpy==1.23.1\npackaging==21.3\npandas==1.4.3\npathtools==0.1.2\npromise==2.3\nprotobuf==3.20.1\npsutil==5.9.1\npyparsing==3.0.9\npython-dateutil==2.8.2\npytz==2022.1\nPyYAML==6.0\nregex==2022.7.9\nrequests==2.28.1\nsentry-sdk==1.7.0\nsetproctitle==1.2.3\nshortuuid==1.0.9\nsix==1.16.0\nsmmap==5.0.0\ntokenizers==0.12.1\ntorch==1.12.0\ntqdm==4.64.0\ntransformers==4.20.1\ntyping_extensions==4.3.0\nurllib3==1.26.10\nwandb==0.12.21\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r requirements.txt ","metadata":{"id":"C5Nmf855c_tr","outputId":"b54764e1-1161-4ba4-8863-a1351d88dd74","execution":{"iopub.status.busy":"2022-07-13T14:34:37.642936Z","iopub.execute_input":"2022-07-13T14:34:37.643316Z","iopub.status.idle":"2022-07-13T14:34:41.109141Z","shell.execute_reply.started":"2022-07-13T14:34:37.643275Z","shell.execute_reply":"2022-07-13T14:34:41.107972Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: certifi==2022.6.15 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (2022.6.15)\nCollecting charset-normalizer==2.1.0\n  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\nCollecting click==8.1.3\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m807.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting colorama==0.4.5\n  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: docker-pycreds==0.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.4.0)\nCollecting filelock==3.7.1\n  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\nRequirement already satisfied: gitdb==4.0.9 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (4.0.9)\nRequirement already satisfied: GitPython==3.1.27 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (3.1.27)\nCollecting huggingface-hub==0.8.1\n  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: idna==3.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (3.3)\n\u001b[31mERROR: Ignored the following versions that require a different python version: 1.22.0 Requires-Python >=3.8; 1.22.0rc1 Requires-Python >=3.8; 1.22.0rc2 Requires-Python >=3.8; 1.22.0rc3 Requires-Python >=3.8; 1.22.1 Requires-Python >=3.8; 1.22.2 Requires-Python >=3.8; 1.22.3 Requires-Python >=3.8; 1.22.4 Requires-Python >=3.8; 1.23.0 Requires-Python >=3.8; 1.23.0rc1 Requires-Python >=3.8; 1.23.0rc2 Requires-Python >=3.8; 1.23.0rc3 Requires-Python >=3.8; 1.23.1 Requires-Python >=3.8\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.23.1 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0rc1, 1.13.0rc2, 1.13.0, 1.13.1, 1.13.3, 1.14.0rc1, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0rc1, 1.17.0rc2, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0rc1, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0rc1, 1.19.0rc2, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0rc1, 1.20.0rc2, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0rc1, 1.21.0rc2, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.23.1\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Обучение и тестирование","metadata":{"id":"ra-Sa2YpWsOu"}},{"cell_type":"code","source":"from ToxicCommentClassifier.inference import Tester\nfrom ToxicCommentClassifier.train import Trainer","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:34:41.110873Z","iopub.execute_input":"2022-07-13T14:34:41.111482Z","iopub.status.idle":"2022-07-13T14:34:49.092217Z","shell.execute_reply.started":"2022-07-13T14:34:41.111438Z","shell.execute_reply":"2022-07-13T14:34:49.091034Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tester = Tester()\ntester.load_model('./e2_loss0.1510_f1_score_0_91563.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:35:21.103432Z","iopub.execute_input":"2022-07-13T14:35:21.104775Z","iopub.status.idle":"2022-07-13T14:35:29.213798Z","shell.execute_reply.started":"2022-07-13T14:35:21.104719Z","shell.execute_reply":"2022-07-13T14:35:29.212761Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"tester.test(test_csv='data_test_public[494].csv', export_file='res.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:35:29.215853Z","iopub.execute_input":"2022-07-13T14:35:29.216285Z","iopub.status.idle":"2022-07-13T14:35:37.468126Z","shell.execute_reply.started":"2022-07-13T14:35:29.216246Z","shell.execute_reply":"2022-07-13T14:35:37.467050Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 91/91 [00:06<00:00, 13.94it/s]","output_type":"stream"},{"name":"stdout","text":"F1 score: 0.9156378600823045\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n14051  Весь мир знает, что свиньи это русские. Это ва...      toxic   \n13291  Речь не о том, что ютуб подсовывает, а о самых...  non-toxic   \n10641  А если аллергия, ещё и звуковые спецэффекты бу...  non-toxic   \n8855                         где купить такую красоту?\\n  non-toxic   \n1948   Почему ты такой тупой ? я ж объяснил на что ко...      toxic   \n...                                                  ...        ...   \n8659   Брат моего соседа по общежитию. Хороший парень...  non-toxic   \n9860   В последние годы снимают откровенный шлак. Не ...  non-toxic   \n8290   Соня неплох, но пока еще дорохо. Вот дексп уже...  non-toxic   \n7196   У нас плотва с икрой, которая крупная где то 8...  non-toxic   \n6769   Похожая история , за стенкой у ребёнка любител...  non-toxic   \n\n      class_prediction  probabilities  \n14051            toxic       0.986826  \n13291        non-toxic       0.995745  \n10641        non-toxic       0.993040  \n8855         non-toxic       0.993106  \n1948             toxic       0.984982  \n...                ...            ...  \n8659         non-toxic       0.854041  \n9860         non-toxic       0.994848  \n8290         non-toxic       0.996567  \n7196         non-toxic       0.996594  \n6769         non-toxic       0.992555  \n\n[1442 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14051</th>\n      <td>Весь мир знает, что свиньи это русские. Это ва...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.986826</td>\n    </tr>\n    <tr>\n      <th>13291</th>\n      <td>Речь не о том, что ютуб подсовывает, а о самых...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.995745</td>\n    </tr>\n    <tr>\n      <th>10641</th>\n      <td>А если аллергия, ещё и звуковые спецэффекты бу...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.993040</td>\n    </tr>\n    <tr>\n      <th>8855</th>\n      <td>где купить такую красоту?\\n</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.993106</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>Почему ты такой тупой ? я ж объяснил на что ко...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.984982</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8659</th>\n      <td>Брат моего соседа по общежитию. Хороший парень...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.854041</td>\n    </tr>\n    <tr>\n      <th>9860</th>\n      <td>В последние годы снимают откровенный шлак. Не ...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.994848</td>\n    </tr>\n    <tr>\n      <th>8290</th>\n      <td>Соня неплох, но пока еще дорохо. Вот дексп уже...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.996567</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>У нас плотва с икрой, которая крупная где то 8...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.996594</td>\n    </tr>\n    <tr>\n      <th>6769</th>\n      <td>Похожая история , за стенкой у ребёнка любител...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.992555</td>\n    </tr>\n  </tbody>\n</table>\n<p>1442 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tester.get_mistakes(print_accs=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:35:37.470339Z","iopub.execute_input":"2022-07-13T14:35:37.471036Z","iopub.status.idle":"2022-07-13T14:35:37.488292Z","shell.execute_reply.started":"2022-07-13T14:35:37.470998Z","shell.execute_reply":"2022-07-13T14:35:37.487214Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"accuracy\t toxic \tnon-toxic\n\t\t0.9736\t0.9695\t","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n8799   А смысл? Сторонники Н все равно ведь ни одному...  non-toxic   \n1355   Так, чисто поржать, ибо пьян.. 1. Ничего лично...  non-toxic   \n5013         Так на стену добавляют, а не удаляют. Не?\\n      toxic   \n1606                              двачую 1 И по традиции      toxic   \n13847  Ошибка: Капча невалидна. Ошибка: Капча невалид...  non-toxic   \n...                                                  ...        ...   \n1942                              Прямо как в полтоРашке  non-toxic   \n12488  походу это тот самый кто звонит и предлагает о...  non-toxic   \n4600                        Сиськи никогда не запретят\\n  non-toxic   \n767                              НА УКРАИНЕ БЕЛОРУССИЯ\\n  non-toxic   \n523    Знаете, шли бы вы ... в баню. Кстати. можете с...  non-toxic   \n\n      class_prediction  probabilities  \n8799             toxic       0.524190  \n1355             toxic       0.719160  \n5013         non-toxic       0.841700  \n1606         non-toxic       0.544808  \n13847            toxic       0.566883  \n...                ...            ...  \n1942             toxic       0.947074  \n12488            toxic       0.640494  \n4600             toxic       0.636721  \n767              toxic       0.986345  \n523              toxic       0.625725  \n\n[82 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8799</th>\n      <td>А смысл? Сторонники Н все равно ведь ни одному...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.524190</td>\n    </tr>\n    <tr>\n      <th>1355</th>\n      <td>Так, чисто поржать, ибо пьян.. 1. Ничего лично...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.719160</td>\n    </tr>\n    <tr>\n      <th>5013</th>\n      <td>Так на стену добавляют, а не удаляют. Не?\\n</td>\n      <td>toxic</td>\n      <td>non-toxic</td>\n      <td>0.841700</td>\n    </tr>\n    <tr>\n      <th>1606</th>\n      <td>двачую 1 И по традиции</td>\n      <td>toxic</td>\n      <td>non-toxic</td>\n      <td>0.544808</td>\n    </tr>\n    <tr>\n      <th>13847</th>\n      <td>Ошибка: Капча невалидна. Ошибка: Капча невалид...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.566883</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1942</th>\n      <td>Прямо как в полтоРашке</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.947074</td>\n    </tr>\n    <tr>\n      <th>12488</th>\n      <td>походу это тот самый кто звонит и предлагает о...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.640494</td>\n    </tr>\n    <tr>\n      <th>4600</th>\n      <td>Сиськи никогда не запретят\\n</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.636721</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>НА УКРАИНЕ БЕЛОРУССИЯ\\n</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.986345</td>\n    </tr>\n    <tr>\n      <th>523</th>\n      <td>Знаете, шли бы вы ... в баню. Кстати. можете с...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.625725</td>\n    </tr>\n  </tbody>\n</table>\n<p>82 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ntrainer = Trainer()\nmodel = trainer.train(train_csv='data_train[493].csv', val_csv='data_test_public[494].csv')","metadata":{"id":"E2bDk1DKqjr5","outputId":"69da55fb-da9f-460e-b8a8-188bf225cc3b","execution":{"iopub.status.busy":"2022-07-13T14:35:37.489919Z","iopub.execute_input":"2022-07-13T14:35:37.490298Z","iopub.status.idle":"2022-07-13T14:47:12.175980Z","shell.execute_reply.started":"2022-07-13T14:35:37.490264Z","shell.execute_reply":"2022-07-13T14:47:12.174827Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bffa533f372c41868b978e75a6f415e5"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/4 [02:40<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4:\n\ttrain_loss: 0.2735\t train_acc: 0.8926\t train_f1_score: 0.8048\n\tval_loss: 0.1624\t val_acc: 0.9416\t val_f1_score: 0.8939\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1/4 [05:23<08:06, 162.25s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4:\n\ttrain_loss: 0.1542\t train_acc: 0.9474\t train_f1_score: 0.9159\n\tval_loss: 0.1552\t val_acc: 0.9451\t val_f1_score: 0.8988\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [08:05<02:41, 161.64s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4:\n\ttrain_loss: 0.1051\t train_acc: 0.9648\t train_f1_score: 0.9418\n\tval_loss: 0.1832\t val_acc: 0.9396\t val_f1_score: 0.8896\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [10:45<00:00, 161.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4:\n\ttrain_loss: 0.0678\t train_acc: 0.9792\t train_f1_score: 0.9639\n\tval_loss: 0.2001\t val_acc: 0.9396\t val_f1_score: 0.8951\n","output_type":"stream"}]},{"cell_type":"code","source":"from ToxicCommentClassifier.inference import Tester\nfrom ToxicCommentClassifier.train import Trainer\n\ntrainer = Trainer()\nmodel = trainer.train(train_csv='data_train[493].csv', val_csv='data_test_public[494].csv', balance=True, wandb_logging=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:47:12.178834Z","iopub.execute_input":"2022-07-13T14:47:12.179445Z","iopub.status.idle":"2022-07-13T14:57:11.548878Z","shell.execute_reply.started":"2022-07-13T14:47:12.179405Z","shell.execute_reply":"2022-07-13T14:57:11.547828Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.12.21 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.18"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/ToxicCommentClassifier/wandb/run-20220713_144942-20dfz3up</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/annkar/ToxicCommentClassifier/runs/20dfz3up\" target=\"_blank\">ancient-violet-10</a></strong> to <a href=\"https://wandb.ai/annkar/ToxicCommentClassifier\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"  0%|          | 0/4 [01:49<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4:\n\ttrain_loss: 0.3093\t train_acc: 0.8771\t train_f1_score: 0.8749\n\tval_loss: 0.1719\t val_acc: 0.9382\t val_f1_score: 0.8921\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1/4 [03:40<05:32, 110.78s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4:\n\ttrain_loss: 0.1662\t train_acc: 0.9444\t train_f1_score: 0.9408\n\tval_loss: 0.1609\t val_acc: 0.9430\t val_f1_score: 0.8983\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [05:31<01:50, 110.31s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4:\n\ttrain_loss: 0.1122\t train_acc: 0.9657\t train_f1_score: 0.9640\n\tval_loss: 0.1904\t val_acc: 0.9341\t val_f1_score: 0.8894\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [07:20<00:00, 110.20s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4:\n\ttrain_loss: 0.0679\t train_acc: 0.9804\t train_f1_score: 0.9796\n\tval_loss: 0.1986\t val_acc: 0.9382\t val_f1_score: 0.8915\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">ancient-violet-10</strong>: <a href=\"https://wandb.ai/annkar/ToxicCommentClassifier/runs/20dfz3up\" target=\"_blank\">https://wandb.ai/annkar/ToxicCommentClassifier/runs/20dfz3up</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}}]},{"cell_type":"code","source":"trainer.test(test_csv='data_test_public[494].csv', export_file='res.csv')","metadata":{"id":"eS2MxelbLQcR","outputId":"21b9d1d7-74b4-4e3c-b1e7-f8e631c9a290","execution":{"iopub.status.busy":"2022-07-13T14:57:11.551297Z","iopub.execute_input":"2022-07-13T14:57:11.551980Z","iopub.status.idle":"2022-07-13T14:57:18.912372Z","shell.execute_reply.started":"2022-07-13T14:57:11.551939Z","shell.execute_reply":"2022-07-13T14:57:18.911307Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 91/91 [00:05<00:00, 16.50it/s]","output_type":"stream"},{"name":"stdout","text":"F1 score: 0.9164149043303121\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n14051  Весь мир знает, что свиньи это русские. Это ва...      toxic   \n13291  Речь не о том, что ютуб подсовывает, а о самых...  non-toxic   \n10641  А если аллергия, ещё и звуковые спецэффекты бу...  non-toxic   \n8855                         где купить такую красоту?\\n  non-toxic   \n1948   Почему ты такой тупой ? я ж объяснил на что ко...      toxic   \n...                                                  ...        ...   \n8659   Брат моего соседа по общежитию. Хороший парень...  non-toxic   \n9860   В последние годы снимают откровенный шлак. Не ...  non-toxic   \n8290   Соня неплох, но пока еще дорохо. Вот дексп уже...  non-toxic   \n7196   У нас плотва с икрой, которая крупная где то 8...  non-toxic   \n6769   Похожая история , за стенкой у ребёнка любител...  non-toxic   \n\n      class_prediction  probabilities  \n14051            toxic       0.988627  \n13291        non-toxic       0.985410  \n10641        non-toxic       0.984081  \n8855         non-toxic       0.942576  \n1948             toxic       0.988122  \n...                ...            ...  \n8659             toxic       0.574750  \n9860         non-toxic       0.983500  \n8290         non-toxic       0.992851  \n7196         non-toxic       0.981587  \n6769         non-toxic       0.984690  \n\n[1442 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14051</th>\n      <td>Весь мир знает, что свиньи это русские. Это ва...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.988627</td>\n    </tr>\n    <tr>\n      <th>13291</th>\n      <td>Речь не о том, что ютуб подсовывает, а о самых...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.985410</td>\n    </tr>\n    <tr>\n      <th>10641</th>\n      <td>А если аллергия, ещё и звуковые спецэффекты бу...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.984081</td>\n    </tr>\n    <tr>\n      <th>8855</th>\n      <td>где купить такую красоту?\\n</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.942576</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>Почему ты такой тупой ? я ж объяснил на что ко...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.988122</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8659</th>\n      <td>Брат моего соседа по общежитию. Хороший парень...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.574750</td>\n    </tr>\n    <tr>\n      <th>9860</th>\n      <td>В последние годы снимают откровенный шлак. Не ...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.983500</td>\n    </tr>\n    <tr>\n      <th>8290</th>\n      <td>Соня неплох, но пока еще дорохо. Вот дексп уже...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.992851</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>У нас плотва с икрой, которая крупная где то 8...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.981587</td>\n    </tr>\n    <tr>\n      <th>6769</th>\n      <td>Похожая история , за стенкой у ребёнка любител...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.984690</td>\n    </tr>\n  </tbody>\n</table>\n<p>1442 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model = trainer.train(train_csv='data_train[493].csv', val_csv='data_test_public[494].csv', batch_sz=2, balance=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:57:18.914031Z","iopub.execute_input":"2022-07-13T14:57:18.914702Z","iopub.status.idle":"2022-07-13T15:16:01.931331Z","shell.execute_reply.started":"2022-07-13T14:57:18.914663Z","shell.execute_reply":"2022-07-13T15:16:01.930232Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/4 [04:36<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4:\n\ttrain_loss: 0.2651\t train_acc: 0.8946\t train_f1_score: 0.6604\n\tval_loss: 0.1701\t val_acc: 0.9376\t val_f1_score: 0.5210\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2/4 [09:13<09:13, 276.68s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4:\n\ttrain_loss: 0.1369\t train_acc: 0.9551\t train_f1_score: 0.7096\n\tval_loss: 0.1800\t val_acc: 0.9376\t val_f1_score: 0.5261\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [13:48<04:35, 275.99s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4:\n\ttrain_loss: 0.0701\t train_acc: 0.9793\t train_f1_score: 0.7367\n\tval_loss: 0.2416\t val_acc: 0.9293\t val_f1_score: 0.5243\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [18:26<00:00, 276.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4:\n\ttrain_loss: 0.0404\t train_acc: 0.9891\t train_f1_score: 0.7443\n\tval_loss: 0.2243\t val_acc: 0.9362\t val_f1_score: 0.5127\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.test(test_csv='data_test_public[494].csv', export_file='res.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:16:01.939783Z","iopub.execute_input":"2022-07-13T15:16:01.940082Z","iopub.status.idle":"2022-07-13T15:16:09.028490Z","shell.execute_reply.started":"2022-07-13T15:16:01.940053Z","shell.execute_reply":"2022-07-13T15:16:09.027502Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 91/91 [00:05<00:00, 16.53it/s]","output_type":"stream"},{"name":"stdout","text":"F1 score: 0.9110671936758893\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n14051  Весь мир знает, что свиньи это русские. Это ва...      toxic   \n13291  Речь не о том, что ютуб подсовывает, а о самых...  non-toxic   \n10641  А если аллергия, ещё и звуковые спецэффекты бу...  non-toxic   \n8855                         где купить такую красоту?\\n  non-toxic   \n1948   Почему ты такой тупой ? я ж объяснил на что ко...      toxic   \n...                                                  ...        ...   \n8659   Брат моего соседа по общежитию. Хороший парень...  non-toxic   \n9860   В последние годы снимают откровенный шлак. Не ...  non-toxic   \n8290   Соня неплох, но пока еще дорохо. Вот дексп уже...  non-toxic   \n7196   У нас плотва с икрой, которая крупная где то 8...  non-toxic   \n6769   Похожая история , за стенкой у ребёнка любител...  non-toxic   \n\n      class_prediction  probabilities  \n14051            toxic       0.989507  \n13291        non-toxic       0.992646  \n10641        non-toxic       0.985912  \n8855         non-toxic       0.982189  \n1948             toxic       0.986133  \n...                ...            ...  \n8659             toxic       0.809004  \n9860         non-toxic       0.964588  \n8290         non-toxic       0.994700  \n7196         non-toxic       0.994415  \n6769         non-toxic       0.939838  \n\n[1442 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14051</th>\n      <td>Весь мир знает, что свиньи это русские. Это ва...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.989507</td>\n    </tr>\n    <tr>\n      <th>13291</th>\n      <td>Речь не о том, что ютуб подсовывает, а о самых...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.992646</td>\n    </tr>\n    <tr>\n      <th>10641</th>\n      <td>А если аллергия, ещё и звуковые спецэффекты бу...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.985912</td>\n    </tr>\n    <tr>\n      <th>8855</th>\n      <td>где купить такую красоту?\\n</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.982189</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>Почему ты такой тупой ? я ж объяснил на что ко...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.986133</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8659</th>\n      <td>Брат моего соседа по общежитию. Хороший парень...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.809004</td>\n    </tr>\n    <tr>\n      <th>9860</th>\n      <td>В последние годы снимают откровенный шлак. Не ...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.964588</td>\n    </tr>\n    <tr>\n      <th>8290</th>\n      <td>Соня неплох, но пока еще дорохо. Вот дексп уже...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.994700</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>У нас плотва с икрой, которая крупная где то 8...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.994415</td>\n    </tr>\n    <tr>\n      <th>6769</th>\n      <td>Похожая история , за стенкой у ребёнка любител...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.939838</td>\n    </tr>\n  </tbody>\n</table>\n<p>1442 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model = trainer.train(train_csv='data_train[493].csv', val_csv='data_test_public[494].csv', batch_sz=2)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:16:09.032075Z","iopub.execute_input":"2022-07-13T15:16:09.032946Z","iopub.status.idle":"2022-07-13T15:43:41.363432Z","shell.execute_reply.started":"2022-07-13T15:16:09.032906Z","shell.execute_reply":"2022-07-13T15:43:41.362452Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/4 [06:47<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4:\n\ttrain_loss: 0.2338\t train_acc: 0.9097\t train_f1_score: 0.4730\n\tval_loss: 0.1573\t val_acc: 0.9445\t val_f1_score: 0.5243\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2/4 [13:36<13:36, 408.17s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4:\n\ttrain_loss: 0.1227\t train_acc: 0.9585\t train_f1_score: 0.5283\n\tval_loss: 0.1756\t val_acc: 0.9397\t val_f1_score: 0.5187\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [20:24<06:48, 408.04s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4:\n\ttrain_loss: 0.0642\t train_acc: 0.9796\t train_f1_score: 0.5442\n\tval_loss: 0.1781\t val_acc: 0.9376\t val_f1_score: 0.4938\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [27:11<00:00, 407.78s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4:\n\ttrain_loss: 0.0351\t train_acc: 0.9899\t train_f1_score: 0.5499\n\tval_loss: 0.2556\t val_acc: 0.9300\t val_f1_score: 0.4822\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.test(test_csv='data_test_public[494].csv', export_file='res.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:43:41.365763Z","iopub.execute_input":"2022-07-13T15:43:41.366230Z","iopub.status.idle":"2022-07-13T15:43:48.499735Z","shell.execute_reply.started":"2022-07-13T15:43:41.366191Z","shell.execute_reply":"2022-07-13T15:43:48.498774Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 91/91 [00:05<00:00, 16.47it/s]","output_type":"stream"},{"name":"stdout","text":"F1 score: 0.9198396793587175\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n14051  Весь мир знает, что свиньи это русские. Это ва...      toxic   \n13291  Речь не о том, что ютуб подсовывает, а о самых...  non-toxic   \n10641  А если аллергия, ещё и звуковые спецэффекты бу...  non-toxic   \n8855                         где купить такую красоту?\\n  non-toxic   \n1948   Почему ты такой тупой ? я ж объяснил на что ко...      toxic   \n...                                                  ...        ...   \n8659   Брат моего соседа по общежитию. Хороший парень...  non-toxic   \n9860   В последние годы снимают откровенный шлак. Не ...  non-toxic   \n8290   Соня неплох, но пока еще дорохо. Вот дексп уже...  non-toxic   \n7196   У нас плотва с икрой, которая крупная где то 8...  non-toxic   \n6769   Похожая история , за стенкой у ребёнка любител...  non-toxic   \n\n      class_prediction  probabilities  \n14051            toxic       0.982531  \n13291        non-toxic       0.980897  \n10641        non-toxic       0.977674  \n8855         non-toxic       0.969741  \n1948             toxic       0.984286  \n...                ...            ...  \n8659         non-toxic       0.635868  \n9860         non-toxic       0.962750  \n8290         non-toxic       0.992878  \n7196         non-toxic       0.994134  \n6769         non-toxic       0.932152  \n\n[1442 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14051</th>\n      <td>Весь мир знает, что свиньи это русские. Это ва...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.982531</td>\n    </tr>\n    <tr>\n      <th>13291</th>\n      <td>Речь не о том, что ютуб подсовывает, а о самых...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.980897</td>\n    </tr>\n    <tr>\n      <th>10641</th>\n      <td>А если аллергия, ещё и звуковые спецэффекты бу...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.977674</td>\n    </tr>\n    <tr>\n      <th>8855</th>\n      <td>где купить такую красоту?\\n</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.969741</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>Почему ты такой тупой ? я ж объяснил на что ко...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.984286</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8659</th>\n      <td>Брат моего соседа по общежитию. Хороший парень...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.635868</td>\n    </tr>\n    <tr>\n      <th>9860</th>\n      <td>В последние годы снимают откровенный шлак. Не ...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.962750</td>\n    </tr>\n    <tr>\n      <th>8290</th>\n      <td>Соня неплох, но пока еще дорохо. Вот дексп уже...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.992878</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>У нас плотва с икрой, которая крупная где то 8...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.994134</td>\n    </tr>\n    <tr>\n      <th>6769</th>\n      <td>Похожая история , за стенкой у ребёнка любител...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.932152</td>\n    </tr>\n  </tbody>\n</table>\n<p>1442 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.get_mistakes(print_accs=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:43:48.501519Z","iopub.execute_input":"2022-07-13T15:43:48.502192Z","iopub.status.idle":"2022-07-13T15:43:48.519519Z","shell.execute_reply.started":"2022-07-13T15:43:48.502154Z","shell.execute_reply":"2022-07-13T15:43:48.518618Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"accuracy\t toxic \tnon-toxic\n\t\t0.9834\t0.9612\t","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n8799   А смысл? Сторонники Н все равно ведь ни одному...  non-toxic   \n1355   Так, чисто поржать, ибо пьян.. 1. Ничего лично...  non-toxic   \n5013         Так на стену добавляют, а не удаляют. Не?\\n      toxic   \n11889         Скорее Спасибо деду за рецепт баварского\\n  non-toxic   \n1606                              двачую 1 И по традиции      toxic   \n...                                                  ...        ...   \n1942                              Прямо как в полтоРашке  non-toxic   \n12488  походу это тот самый кто звонит и предлагает о...  non-toxic   \n269    Если такое мнение тебя утешает - можешь продол...  non-toxic   \n767                              НА УКРАИНЕ БЕЛОРУССИЯ\\n  non-toxic   \n523    Знаете, шли бы вы ... в баню. Кстати. можете с...  non-toxic   \n\n      class_prediction  probabilities  \n8799             toxic       0.613068  \n1355             toxic       0.839948  \n5013         non-toxic       0.584807  \n11889            toxic       0.536082  \n1606         non-toxic       0.534482  \n...                ...            ...  \n1942             toxic       0.873192  \n12488            toxic       0.565349  \n269              toxic       0.634284  \n767              toxic       0.978459  \n523              toxic       0.791128  \n\n[80 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8799</th>\n      <td>А смысл? Сторонники Н все равно ведь ни одному...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.613068</td>\n    </tr>\n    <tr>\n      <th>1355</th>\n      <td>Так, чисто поржать, ибо пьян.. 1. Ничего лично...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.839948</td>\n    </tr>\n    <tr>\n      <th>5013</th>\n      <td>Так на стену добавляют, а не удаляют. Не?\\n</td>\n      <td>toxic</td>\n      <td>non-toxic</td>\n      <td>0.584807</td>\n    </tr>\n    <tr>\n      <th>11889</th>\n      <td>Скорее Спасибо деду за рецепт баварского\\n</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.536082</td>\n    </tr>\n    <tr>\n      <th>1606</th>\n      <td>двачую 1 И по традиции</td>\n      <td>toxic</td>\n      <td>non-toxic</td>\n      <td>0.534482</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1942</th>\n      <td>Прямо как в полтоРашке</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.873192</td>\n    </tr>\n    <tr>\n      <th>12488</th>\n      <td>походу это тот самый кто звонит и предлагает о...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.565349</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>Если такое мнение тебя утешает - можешь продол...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.634284</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>НА УКРАИНЕ БЕЛОРУССИЯ\\n</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.978459</td>\n    </tr>\n    <tr>\n      <th>523</th>\n      <td>Знаете, шли бы вы ... в баню. Кстати. можете с...</td>\n      <td>non-toxic</td>\n      <td>toxic</td>\n      <td>0.791128</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"trainer = Trainer()\nmodel = trainer.train(train_csv='data_train[493].csv', val_csv='data_test_public[494].csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:43:48.539866Z","iopub.execute_input":"2022-07-13T15:43:48.540526Z","iopub.status.idle":"2022-07-13T15:54:55.680138Z","shell.execute_reply.started":"2022-07-13T15:43:48.540491Z","shell.execute_reply":"2022-07-13T15:54:55.679099Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/4 [02:40<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4:\n\ttrain_loss: 0.2662\t train_acc: 0.8914\t train_f1_score: 0.7987\n\tval_loss: 0.1631\t val_acc: 0.9409\t val_f1_score: 0.8944\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1/4 [05:22<08:05, 161.78s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4:\n\ttrain_loss: 0.1570\t train_acc: 0.9441\t train_f1_score: 0.9109\n\tval_loss: 0.1574\t val_acc: 0.9396\t val_f1_score: 0.8925\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [08:03<02:41, 161.17s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4:\n\ttrain_loss: 0.1050\t train_acc: 0.9646\t train_f1_score: 0.9427\n\tval_loss: 0.1810\t val_acc: 0.9416\t val_f1_score: 0.8977\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [10:44<00:00, 161.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4:\n\ttrain_loss: 0.0636\t train_acc: 0.9801\t train_f1_score: 0.9666\n\tval_loss: 0.1966\t val_acc: 0.9402\t val_f1_score: 0.8948\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.test(test_csv='data_test_public[494].csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:54:55.682438Z","iopub.execute_input":"2022-07-13T15:54:55.682825Z","iopub.status.idle":"2022-07-13T15:55:02.735355Z","shell.execute_reply.started":"2022-07-13T15:54:55.682788Z","shell.execute_reply":"2022-07-13T15:55:02.734293Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"100%|██████████| 91/91 [00:05<00:00, 16.59it/s]","output_type":"stream"},{"name":"stdout","text":"F1 score: 0.9102040816326531\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n14051  Весь мир знает, что свиньи это русские. Это ва...      toxic   \n13291  Речь не о том, что ютуб подсовывает, а о самых...  non-toxic   \n10641  А если аллергия, ещё и звуковые спецэффекты бу...  non-toxic   \n8855                         где купить такую красоту?\\n  non-toxic   \n1948   Почему ты такой тупой ? я ж объяснил на что ко...      toxic   \n...                                                  ...        ...   \n8659   Брат моего соседа по общежитию. Хороший парень...  non-toxic   \n9860   В последние годы снимают откровенный шлак. Не ...  non-toxic   \n8290   Соня неплох, но пока еще дорохо. Вот дексп уже...  non-toxic   \n7196   У нас плотва с икрой, которая крупная где то 8...  non-toxic   \n6769   Похожая история , за стенкой у ребёнка любител...  non-toxic   \n\n      class_prediction  probabilities  \n14051            toxic       0.988703  \n13291        non-toxic       0.994516  \n10641        non-toxic       0.995405  \n8855         non-toxic       0.994088  \n1948             toxic       0.987881  \n...                ...            ...  \n8659         non-toxic       0.787407  \n9860         non-toxic       0.995549  \n8290         non-toxic       0.996724  \n7196         non-toxic       0.993973  \n6769         non-toxic       0.958186  \n\n[1442 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14051</th>\n      <td>Весь мир знает, что свиньи это русские. Это ва...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.988703</td>\n    </tr>\n    <tr>\n      <th>13291</th>\n      <td>Речь не о том, что ютуб подсовывает, а о самых...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.994516</td>\n    </tr>\n    <tr>\n      <th>10641</th>\n      <td>А если аллергия, ещё и звуковые спецэффекты бу...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.995405</td>\n    </tr>\n    <tr>\n      <th>8855</th>\n      <td>где купить такую красоту?\\n</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.994088</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>Почему ты такой тупой ? я ж объяснил на что ко...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.987881</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8659</th>\n      <td>Брат моего соседа по общежитию. Хороший парень...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.787407</td>\n    </tr>\n    <tr>\n      <th>9860</th>\n      <td>В последние годы снимают откровенный шлак. Не ...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.995549</td>\n    </tr>\n    <tr>\n      <th>8290</th>\n      <td>Соня неплох, но пока еще дорохо. Вот дексп уже...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.996724</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>У нас плотва с икрой, которая крупная где то 8...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.993973</td>\n    </tr>\n    <tr>\n      <th>6769</th>\n      <td>Похожая история , за стенкой у ребёнка любител...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.958186</td>\n    </tr>\n  </tbody>\n</table>\n<p>1442 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model2 = trainer.train(train_csv='data_train[493].csv', val_csv='data_test_public[494].csv', batch_sz=2, wandb_logging=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:55:02.737159Z","iopub.execute_input":"2022-07-13T15:55:02.737905Z","iopub.status.idle":"2022-07-13T16:23:00.718142Z","shell.execute_reply.started":"2022-07-13T15:55:02.737866Z","shell.execute_reply":"2022-07-13T16:23:00.717025Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mannkar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.12.21 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.18"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/ToxicCommentClassifier/wandb/run-20220713_155523-1yqs5hne</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/annkar/ToxicCommentClassifier/runs/1yqs5hne\" target=\"_blank\">volcanic-field-11</a></strong> to <a href=\"https://wandb.ai/annkar/ToxicCommentClassifier\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"  0%|          | 0/4 [06:47<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4:\n\ttrain_loss: 0.2345\t train_acc: 0.9068\t train_f1_score: 0.4728\n\tval_loss: 0.1510\t val_acc: 0.9417\t val_f1_score: 0.5058\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2/4 [13:41<13:41, 410.97s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4:\n\ttrain_loss: 0.1274\t train_acc: 0.9542\t train_f1_score: 0.5227\n\tval_loss: 0.1561\t val_acc: 0.9459\t val_f1_score: 0.5183\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [20:35<06:52, 412.50s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4:\n\ttrain_loss: 0.0667\t train_acc: 0.9785\t train_f1_score: 0.5387\n\tval_loss: 0.1809\t val_acc: 0.9424\t val_f1_score: 0.5090\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [27:28<00:00, 412.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4:\n\ttrain_loss: 0.0372\t train_acc: 0.9888\t train_f1_score: 0.5504\n\tval_loss: 0.2096\t val_acc: 0.9348\t val_f1_score: 0.4864\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">volcanic-field-11</strong>: <a href=\"https://wandb.ai/annkar/ToxicCommentClassifier/runs/1yqs5hne\" target=\"_blank\">https://wandb.ai/annkar/ToxicCommentClassifier/runs/1yqs5hne</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}}]},{"cell_type":"code","source":"trainer.test(test_csv='data_test_public[494].csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T16:23:00.721033Z","iopub.execute_input":"2022-07-13T16:23:00.721632Z","iopub.status.idle":"2022-07-13T16:23:07.863104Z","shell.execute_reply.started":"2022-07-13T16:23:00.721589Z","shell.execute_reply":"2022-07-13T16:23:07.862026Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"100%|██████████| 91/91 [00:05<00:00, 16.39it/s]","output_type":"stream"},{"name":"stdout","text":"F1 score: 0.9134020618556701\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                                    text class_true  \\\n14051  Весь мир знает, что свиньи это русские. Это ва...      toxic   \n13291  Речь не о том, что ютуб подсовывает, а о самых...  non-toxic   \n10641  А если аллергия, ещё и звуковые спецэффекты бу...  non-toxic   \n8855                         где купить такую красоту?\\n  non-toxic   \n1948   Почему ты такой тупой ? я ж объяснил на что ко...      toxic   \n...                                                  ...        ...   \n8659   Брат моего соседа по общежитию. Хороший парень...  non-toxic   \n9860   В последние годы снимают откровенный шлак. Не ...  non-toxic   \n8290   Соня неплох, но пока еще дорохо. Вот дексп уже...  non-toxic   \n7196   У нас плотва с икрой, которая крупная где то 8...  non-toxic   \n6769   Похожая история , за стенкой у ребёнка любител...  non-toxic   \n\n      class_prediction  probabilities  \n14051            toxic       0.984399  \n13291        non-toxic       0.994590  \n10641        non-toxic       0.992593  \n8855         non-toxic       0.995499  \n1948             toxic       0.955301  \n...                ...            ...  \n8659         non-toxic       0.946904  \n9860         non-toxic       0.992613  \n8290         non-toxic       0.996305  \n7196         non-toxic       0.996189  \n6769         non-toxic       0.987352  \n\n[1442 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class_true</th>\n      <th>class_prediction</th>\n      <th>probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14051</th>\n      <td>Весь мир знает, что свиньи это русские. Это ва...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.984399</td>\n    </tr>\n    <tr>\n      <th>13291</th>\n      <td>Речь не о том, что ютуб подсовывает, а о самых...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.994590</td>\n    </tr>\n    <tr>\n      <th>10641</th>\n      <td>А если аллергия, ещё и звуковые спецэффекты бу...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.992593</td>\n    </tr>\n    <tr>\n      <th>8855</th>\n      <td>где купить такую красоту?\\n</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.995499</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>Почему ты такой тупой ? я ж объяснил на что ко...</td>\n      <td>toxic</td>\n      <td>toxic</td>\n      <td>0.955301</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8659</th>\n      <td>Брат моего соседа по общежитию. Хороший парень...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.946904</td>\n    </tr>\n    <tr>\n      <th>9860</th>\n      <td>В последние годы снимают откровенный шлак. Не ...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.992613</td>\n    </tr>\n    <tr>\n      <th>8290</th>\n      <td>Соня неплох, но пока еще дорохо. Вот дексп уже...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.996305</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>У нас плотва с икрой, которая крупная где то 8...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.996189</td>\n    </tr>\n    <tr>\n      <th>6769</th>\n      <td>Похожая история , за стенкой у ребёнка любител...</td>\n      <td>non-toxic</td>\n      <td>non-toxic</td>\n      <td>0.987352</td>\n    </tr>\n  </tbody>\n</table>\n<p>1442 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model = trainer.train(train_csv='data_train[493].csv', val_csv='data_test_public[494].csv', balance=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T16:23:07.865049Z","iopub.execute_input":"2022-07-13T16:23:07.865399Z","iopub.status.idle":"2022-07-13T16:30:45.610375Z","shell.execute_reply.started":"2022-07-13T16:23:07.865364Z","shell.execute_reply":"2022-07-13T16:30:45.609396Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|          | 0/4 [01:49<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4:\n\ttrain_loss: 0.3074\t train_acc: 0.8786\t train_f1_score: 0.8706\n\tval_loss: 0.1989\t val_acc: 0.9224\t val_f1_score: 0.8725\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1/4 [03:40<05:32, 110.96s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4:\n\ttrain_loss: 0.1663\t train_acc: 0.9436\t train_f1_score: 0.9413\n\tval_loss: 0.1658\t val_acc: 0.9423\t val_f1_score: 0.8984\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3/4 [05:31<01:50, 110.39s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4:\n\ttrain_loss: 0.1077\t train_acc: 0.9677\t train_f1_score: 0.9659\n\tval_loss: 0.1714\t val_acc: 0.9389\t val_f1_score: 0.8933\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [07:21<00:00, 110.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4:\n\ttrain_loss: 0.0705\t train_acc: 0.9798\t train_f1_score: 0.9794\n\tval_loss: 0.1896\t val_acc: 0.9423\t val_f1_score: 0.8990\n","output_type":"stream"}]}]}